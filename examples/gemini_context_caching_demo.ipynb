{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2479283e",
   "metadata": {},
   "source": [
    "# Context Caching with Gemini 3 Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b03a5",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Knowledge Base\n",
    "\n",
    "We'll initialize the interpreter with **context caching enabled** and set up our knowledge base. While caching with Gemini is enabled *by default*, we'll explicitly demonstrate the API configuration here.\n",
    "\n",
    "For our proprietary document proxy, we're using the **WMO State of the Global Climate 2025 Update** (presented at COP30). This report was chosen specifically because its publication date (November 4, 2025) falls *after* the knowledge cutoff for the Gemini 3 model family (January 2025), ensuring the model relies solely on the provided context.\n",
    "\n",
    "For details on how `kanoa` handles file uploads to Google, please refer to the [Gemini Backend Documentation](../docs/source/backends/gemini.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d036b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"background: rgba(186, 164, 217, 0.12);\n",
       "            border: 1px solid rgba(186, 164, 217, 0.35);\n",
       "            border-left: 3px solid rgba(186, 164, 217, 0.75);\n",
       "            padding: 14px 18px;\n",
       "            margin: 10px 0;\n",
       "            border-radius: 6px;\n",
       "            font-size: 0.9em;\n",
       "            line-height: 1.5;\n",
       "            font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Mono', 'Droid Sans Mono', 'Source Code Pro', monospace;\">\n",
       "\n",
       "<div style=\"font-weight: 600; margin-bottom: 10px; font-size: 1.05em; opacity: 0.9;\">kanoa</div>\n",
       "<div style=\"opacity: 0.85;\">Authenticating with Google Cloud (Model: gemini-3-pro-preview)...</div>\n",
       "<div style=\"opacity: 0.85;\">Downloading https://wmo.int/sites/default/files/2025-11/State%20of%20the%20Climate%202025%20Update%20COP30%20%2831%20oct%29.pdf to knowledge_base_demo/State of the Climate 2025 Update COP30 (31 oct).pdf...</div>\n",
       "<div style=\"opacity: 0.85;\">Found 1 PDFs to process...</div>\n",
       "<div style=\"opacity: 0.85;\">Processing PDF: State of the Climate 2025 Update COP30 (31 oct).pdf (8.59 MB)</div>\n",
       "<div style=\"opacity: 0.85;\">Using inline transfer (Vertex AI)...</div>\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Backend: gemini-3\n",
      "Cache TTL: 3600s\n",
      "Knowledge Base: knowledge_base_demo/State of the Climate 2025 Update COP30 (31 oct).pdf\n",
      "File Size: 8.59 MB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import kanoa\n",
    "from kanoa import AnalyticsInterpreter\n",
    "\n",
    "# 1. Configuration\n",
    "# Set global verbosity (True = Info/Uploads, 2 = Debug/Payloads)\n",
    "kanoa.options.verbose = True\n",
    "\n",
    "# 2. Define Knowledge Base Resources\n",
    "# We use the WMO State of the Climate 2025 Update PDF\n",
    "KB_FILENAME = \"State of the Climate 2025 Update COP30 (31 oct).pdf\"\n",
    "KB_DIR = Path(\"knowledge_base_demo\")\n",
    "\n",
    "# The URL contains spaces and parentheses, which kanoa handles automatically\n",
    "KB_URL = f\"https://wmo.int/sites/default/files/2025-11/{KB_FILENAME}\"\n",
    "\n",
    "# 3. Initialize Interpreter with Caching\n",
    "# cache_ttl=3600 means the cache is valid for 1 hour\n",
    "interpreter = AnalyticsInterpreter(\n",
    "    backend=\"gemini-3\",\n",
    "    cache_ttl=3600,\n",
    ")\n",
    "\n",
    "# 4. Attach Knowledge Base & Add Resource\n",
    "# We explicitly set the path to keep files in the example folder\n",
    "interpreter = interpreter.with_kb(kb_path=KB_DIR, kb_type=\"pdf\")\n",
    "\n",
    "# This downloads the file if missing, or verifies it exists\n",
    "# We don't need to pass filename; kanoa infers it from the URL\n",
    "KB_PATH = interpreter.get_kb().add_resource(uri=KB_URL)\n",
    "\n",
    "# 5. Trigger Load & Verify\n",
    "# This will trigger the upload to Gemini (if not cached) and print status\n",
    "interpreter.get_kb().get_context()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Backend: {interpreter.backend_name}\")\n",
    "print(f\"Cache TTL: {interpreter.backend.cache_ttl_seconds}s\")\n",
    "print(f\"Knowledge Base: {KB_PATH}\")\n",
    "print(f\"File Size: {KB_PATH.stat().st_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9fcea",
   "metadata": {},
   "source": [
    "## Step 2: Verify Token Count\n",
    "\n",
    "Before running our query, let's verify the token count of our PDF knowledge base.\n",
    "This helps us understand the scale of the context we're caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e43849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Base Token Check:\n",
      "Status: WARN\n",
      "Token Count: 9,520\n",
      "Estimated Cost: $0.0190\n",
      "Message: 9,520 tokens, ~$0.0190\n"
     ]
    }
   ],
   "source": [
    "# Use the interpreter's built-in cost checker to verify token count and cost\n",
    "# This validates against warning/approval thresholds\n",
    "result = interpreter.check_kb_cost()\n",
    "\n",
    "if result:\n",
    "    print(\"Knowledge Base Token Check:\")\n",
    "    print(f\"Status: {result.level.upper()}\")\n",
    "    print(f\"Token Count: {result.token_count:,}\")\n",
    "    print(f\"Estimated Cost: ${result.estimated_cost:.4f}\")\n",
    "    print(f\"Message: {result.message}\")\n",
    "else:\n",
    "    print(\"No files uploaded or backend does not support file uploads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea719d5",
   "metadata": {},
   "source": [
    "### Checking Cache Status\n",
    "\n",
    "You can check the status of the context cache for your current knowledge base without running a query. This is useful for verifying if a cache exists and inspecting its properties (TTL, token count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce1a353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cache status:\n",
      "{\n",
      "  \"exists\": false,\n",
      "  \"hash\": \"ba7ca903782c0509\",\n",
      "  \"reason\": \"Not found\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Check cache status\n",
    "status = interpreter.get_cache_status()\n",
    "\n",
    "print(\"Current cache status:\")\n",
    "print(json.dumps(status, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e23820",
   "metadata": {},
   "source": [
    "## Step 3: First Query (Cache Miss)\n",
    "\n",
    "The first query will upload the knowledge base and create a cache.\n",
    "You'll see the full token cost for the KB content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea71ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"background: rgba(186, 164, 217, 0.12);\n",
       "            border: 1px solid rgba(186, 164, 217, 0.35);\n",
       "            border-left: 3px solid rgba(186, 164, 217, 0.75);\n",
       "            padding: 14px 18px;\n",
       "            margin: 10px 0;\n",
       "            border-radius: 6px;\n",
       "            font-size: 0.9em;\n",
       "            line-height: 1.5;\n",
       "            font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Mono', 'Droid Sans Mono', 'Source Code Pro', monospace;\">\n",
       "\n",
       "<div style=\"font-weight: 600; margin-bottom: 10px; font-size: 1.05em; opacity: 0.9;\">kanoa</div>\n",
       "<div style=\"opacity: 0.85;\">⚡ Cache Check: Checking context cache (Hash: ba7ca903782c0509)</div>\n",
       "<div style=\"opacity: 0.85;\">Checking server for existing cache: kanoa-kb-ba7ca903782c0509...</div>\n",
       "<div style=\"opacity: 0.85;\">Creating new cache on models/gemini-3-pro-preview...</div>\n",
       "<div style=\"opacity: 0.85;\">✓ Cache Created: Cache created: projects/830895911586/locations/global/cachedContents/8689122360575393792 (9,068 tokens)</div>\n",
       "<div style=\"opacity: 0.85;\">Generating content with gemini-3-pro-preview...</div>\n",
       "<div style=\"opacity: 0.85;\">Cache: Using cached context: projects/830895911586/locations/global/cachedContents/8689122360575393792</div>\n",
       "<div style=\"opacity: 0.85;\">Usage: 9,088 in / 278 out</div>\n",
       "<div style=\"opacity: 0.85;\">Cached tokens: 9,068</div>\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"background: rgba(2, 62, 138, 0.08);\n",
       "            border: 1px solid rgba(2, 62, 138, 0.3);\n",
       "            border-left: 4px solid rgba(2, 62, 138, 0.8);\n",
       "            padding: 16px 20px;\n",
       "            margin: 10px 0;\n",
       "            border-radius: 8px;\n",
       "            backdrop-filter: blur(5px);\n",
       "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);\">\n",
       "\n",
       "<div style=\"font-weight: 600; margin-bottom: 12px; opacity: 0.9; font-size: 1.05em; font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Mono', 'Droid Sans Mono', 'Source Code Pro', monospace;\">gemini-3</div>\n",
       "\n",
       "Based on the \"State of the Climate 2025 Update for COP30\" report, here are the key findings regarding global temperature anomalies for 2025:\n",
       "\n",
       "*   **Temperature Anomaly:** From January to August 2025, the global mean near-surface temperature was **$1.42^\\circ\\text{C} \\pm 0.12^\\circ\\text{C}$** above the pre-industrial average.\n",
       "*   **Historical Ranking:** The year 2025 is on track to be the **second or third warmest year on record**, ranking just behind 2024.\n",
       "*   **Long-Term Trend:** The past 11 years (2015–2025) will individually rank as the **11 warmest years** in the 176-year observational record. The most recent three years are the three warmest on record.\n",
       "*   **Climate Drivers:** The slight drop in temperature compared to the record highs of 2024 is consistent with a shift from **El Niño conditions** (which boosted global temperatures in 2023 and 2024) to **neutral conditions** at the start of 2025. However, reductions in aerosols and other factors likely contributed to the continued high heat.\n",
       "\n",
       "---\n",
       "<small>**gemini-3-pro-preview** · 9,088→278 tokens (9,068 cached) · $0.0215 · cache created</small>\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FIRST QUERY RESULTS (Cache Creation)\n",
      "============================================================\n",
      "\n",
      "Response:\n",
      "Based on the \"State of the Climate 2025 Update for COP30\" report, here are the key findings regarding global temperature anomalies for 2025:\n",
      "\n",
      "*   **Temperature Anomaly:** From January to August 2025, the global mean near-surface temperature was **$1.42^\\circ\\text{C} \\pm 0.12^\\circ\\text{C}$** above the pre-industrial average.\n",
      "*   **Historical Ranking:** The year 2025 is on track to be the **second or third warmest year on record**, ranking just behind 2024.\n",
      "*   **Long-Term Trend:** The past 11 ye...\n",
      "\n",
      "Input tokens:  9,088\n",
      "Output tokens: 278\n",
      "Cached tokens: 9,068\n",
      "Cache savings: $0.0000 (Cache Creation)\n"
     ]
    }
   ],
   "source": [
    "# First query - this creates the cache\n",
    "result1 = interpreter.interpret(\n",
    "    custom_prompt=\"Summarize the key findings regarding global temperature anomalies in 2025 from the WMO report.\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FIRST QUERY RESULTS (Cache Creation)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nResponse:\\n{result1.text[:500]}...\\n\")\n",
    "\n",
    "if result1.usage:\n",
    "    print(f\"Input tokens:  {result1.usage.input_tokens:,}\")\n",
    "    print(f\"Output tokens: {result1.usage.output_tokens:,}\")\n",
    "    print(f\"Cached tokens: {result1.usage.cached_tokens or 0:,}\")\n",
    "    print(\"Cache savings: $0.0000 (Cache Creation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa3a6c",
   "metadata": {},
   "source": [
    "## Step 4: Second Query (Cache Hit)\n",
    "\n",
    "The second query reuses the cached knowledge base.\n",
    "Notice the **cached tokens** are now non-zero, and **cache savings** shows the cost reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9714058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"background: rgba(186, 164, 217, 0.12);\n",
       "            border: 1px solid rgba(186, 164, 217, 0.35);\n",
       "            border-left: 3px solid rgba(186, 164, 217, 0.75);\n",
       "            padding: 14px 18px;\n",
       "            margin: 10px 0;\n",
       "            border-radius: 6px;\n",
       "            font-size: 0.9em;\n",
       "            line-height: 1.5;\n",
       "            font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Mono', 'Droid Sans Mono', 'Source Code Pro', monospace;\">\n",
       "\n",
       "<div style=\"font-weight: 600; margin-bottom: 10px; font-size: 1.05em; opacity: 0.9;\">kanoa</div>\n",
       "<div style=\"opacity: 0.85;\">⚡ Cache Check: Checking context cache (Hash: ba7ca903782c0509)</div>\n",
       "<div style=\"opacity: 0.85;\">⚡ Cache Hit: Cache hit (Memory)! Refreshing TTL for projects/830895911586/locations/global/cachedContents/8689122360575393792</div>\n",
       "<div style=\"opacity: 0.85;\">Generating content with gemini-3-pro-preview...</div>\n",
       "<div style=\"opacity: 0.85;\">Cache: Using cached context: projects/830895911586/locations/global/cachedContents/8689122360575393792</div>\n",
       "<div style=\"opacity: 0.85;\">Usage: 9,087 in / 196 out</div>\n",
       "<div style=\"opacity: 0.85;\">Cached tokens: 9,068</div>\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"background: rgba(2, 62, 138, 0.08);\n",
       "            border: 1px solid rgba(2, 62, 138, 0.3);\n",
       "            border-left: 4px solid rgba(2, 62, 138, 0.8);\n",
       "            padding: 16px 20px;\n",
       "            margin: 10px 0;\n",
       "            border-radius: 8px;\n",
       "            backdrop-filter: blur(5px);\n",
       "            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);\">\n",
       "\n",
       "<div style=\"font-weight: 600; margin-bottom: 12px; opacity: 0.9; font-size: 1.05em; font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Mono', 'Droid Sans Mono', 'Source Code Pro', monospace;\">gemini-3</div>\n",
       "\n",
       "Based on the provided document, **there are no specific outcomes or decisions from COP30 regarding climate finance mentioned.**\n",
       "\n",
       "The document, titled \"State of the Climate Update for COP30,\" is a scientific report prepared to **inform the discussions** at the conference rather than report on its political or financial conclusions.\n",
       "\n",
       "Key points regarding the document's purpose and content include:\n",
       "*   **Purpose:** Page 3 states the update is intended to be a \"science-based reference to anchor COP negotiations in authoritative evidence\" and to \"inform discussions.\"\n",
       "*   **Content:** The report focuses entirely on physical climate indicators (Greenhouse gases, global temperature, ocean heat, sea-level rise, glaciers, sea-ice, and extreme weather events) and the status of early warning systems and renewable energy.\n",
       "*   **Timing:** As an input document provided to the conference, it predates the final decisions and agreements typically reached at the conclusion of a COP summit.\n",
       "\n",
       "---\n",
       "<small>**gemini-3-pro-preview** · 9,087→196 tokens (9,068 cached) · $0.0069 · cached</small>\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SECOND QUERY RESULTS (Cache Hit)\n",
      "============================================================\n",
      "\n",
      "Response:\n",
      "Based on the provided document, **there are no specific outcomes or decisions from COP30 regarding climate finance mentioned.**\n",
      "\n",
      "The document, titled \"State of the Climate Update for COP30,\" is a scientific report prepared to **inform the discussions** at the conference rather than report on its political or financial conclusions.\n",
      "\n",
      "Key points regarding the document's purpose and content include:\n",
      "*   **Purpose:** Page 3 states the update is intended to be a \"science-based reference to anchor COP ...\n",
      "\n",
      "Input tokens:  9,087\n",
      "Output tokens: 196\n",
      "Cached tokens: 9,068\n",
      "Cache savings: $0.0136\n"
     ]
    }
   ],
   "source": [
    "# Second query - this reuses the cache\n",
    "result2 = interpreter.interpret(\n",
    "    custom_prompt=\"What specific outcomes or decisions from COP30 in Belem are mentioned in relation to climate finance?\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SECOND QUERY RESULTS (Cache Hit)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nResponse:\\n{result2.text[:500]}...\\n\")\n",
    "\n",
    "if result2.usage:\n",
    "    print(f\"Input tokens:  {result2.usage.input_tokens:,}\")\n",
    "    print(f\"Output tokens: {result2.usage.output_tokens:,}\")\n",
    "    print(f\"Cached tokens: {result2.usage.cached_tokens or 0:,}\")\n",
    "    print(f\"Cache savings: ${result2.usage.cache_savings or 0.0:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d04ed",
   "metadata": {},
   "source": [
    "## Understanding Cost Savings\n",
    "\n",
    "Context caching provides significant cost savings for repeated queries.\n",
    "\n",
    "For the most up-to-date pricing and a detailed breakdown of costs (including cache storage), please refer to the [Gemini Backend Pricing Documentation](../docs/source/backends/gemini.md#pricing).\n",
    "\n",
    "**Savings formula**: `(cached_tokens / 1M) * (Standard_Price - Cached_Price) = savings`\n",
    "\n",
    "For a 10,000 token knowledge base queried 10 times (using typical savings rates):\n",
    "- Without caching: `10 × 10,000 × $2.00/1M = $0.20`\n",
    "- With caching: `10,000 × $2.00/1M + 9 × 10,000 × $0.50/1M = $0.065`\n",
    "- **~67% savings!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4809f488",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "kanoa's context caching feature:\n",
    "\n",
    "1. **Automatically** caches your knowledge base content\n",
    "2. **Reuses** the cache for subsequent queries (same content hash)\n",
    "3. **Saves ~75%** on input token costs for cached content\n",
    "4. **Tracks** cached tokens and savings in the `UsageInfo` object\n",
    "\n",
    "### When to Use Context Caching\n",
    "\n",
    "- ✅ Interactive analysis sessions with multiple queries\n",
    "- ✅ Batch processing against a stable knowledge base\n",
    "- ✅ Knowledge bases > 2,048 tokens (minimum for caching benefit)\n",
    "\n",
    "### When NOT to Use Context Caching\n",
    "\n",
    "- ❌ Single-shot queries (cache creation overhead)\n",
    "- ❌ Rapidly changing knowledge bases\n",
    "- ❌ Very small knowledge bases (< 2,048 tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kanoa-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
