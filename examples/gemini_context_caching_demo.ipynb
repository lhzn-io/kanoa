{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2479283e",
   "metadata": {},
   "source": [
    "# Context Caching with Gemini 3 Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b03a5",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Knowledge Base\n",
    "\n",
    "We'll initialize the interpreter with **context caching enabled** and set up our knowledge base. While *caching with Gemini is enabled by default*, we'll explicitly demonstrate the API configuration here.\n",
    "\n",
    "For our proprietary document proxy, we're using the **WMO State of the Global Climate 2025 Update** (presented at COP30). This report was chosen specifically because its publication date (November 4, 2025) falls *after* the knowledge cutoff for the Gemini 3 model family (January 2025), ensuring the model relies solely on the provided context.\n",
    "\n",
    "For details on how `kanoa` handles file uploads to Google, please refer to the [Gemini Backend Documentation](../docs/source/backends/gemini.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d036b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import kanoa\n",
    "from kanoa import AnalyticsInterpreter\n",
    "\n",
    "# 1. Configuration\n",
    "# Set global verbosity (True = Info/Uploads, 2 = Debug/Payloads)\n",
    "kanoa.options.verbose = True\n",
    "\n",
    "# 2. Define Knowledge Base Resources\n",
    "# We use the WMO State of the Climate 2025 Update PDF\n",
    "KB_FILENAME = \"State of the Climate 2025 Update COP30 (31 oct).pdf\"\n",
    "KB_DIR = Path(\"knowledge_base_demo\")\n",
    "\n",
    "# The URL contains spaces and parentheses, which kanoa handles automatically\n",
    "KB_URL = f\"https://wmo.int/sites/default/files/2025-11/{KB_FILENAME}\"\n",
    "\n",
    "# 3. Initialize Interpreter with Caching\n",
    "# cache_ttl=3600 means the cache is valid for 1 hour\n",
    "interpreter = AnalyticsInterpreter(\n",
    "    backend=\"gemini-3\",\n",
    "    cache_ttl=3600,\n",
    ")\n",
    "\n",
    "# 4. Attach Knowledge Base & Add Resource\n",
    "# We explicitly set the path to keep files in the example folder\n",
    "interpreter = interpreter.with_kb(kb_path=KB_DIR, kb_type=\"pdf\")\n",
    "\n",
    "# This downloads the file if missing, or verifies it exists\n",
    "# We don't need to pass filename; kanoa infers it from the URL\n",
    "KB_PATH = interpreter.get_kb().add_resource(uri=KB_URL)\n",
    "\n",
    "# 5. Trigger Load & Verify\n",
    "# This will trigger the upload to Gemini (if not cached) and print status\n",
    "interpreter.get_kb().get_context()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Backend: {interpreter.backend_name}\")\n",
    "print(f\"Cache TTL: {interpreter.backend.cache_ttl_seconds}s\")\n",
    "print(f\"Knowledge Base: {KB_PATH}\")\n",
    "print(f\"File Size: {KB_PATH.stat().st_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9fcea",
   "metadata": {},
   "source": [
    "## Step 2: Verify Token Count\n",
    "\n",
    "Before running our query, let's verify the token count of our PDF knowledge base.\n",
    "This helps us understand the scale of the context we're caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e43849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the interpreter's built-in cost checker to verify token count and cost\n",
    "# This validates against warning/approval thresholds\n",
    "result = interpreter.check_kb_cost()\n",
    "\n",
    "if result:\n",
    "    print(\"Knowledge Base Token Check:\")\n",
    "    print(f\"Status: {result.level.upper()}\")\n",
    "    print(f\"Token Count: {result.token_count:,}\")\n",
    "    print(f\"Estimated Cost: ${result.estimated_cost:.4f}\")\n",
    "    print(f\"Message: {result.message}\")\n",
    "else:\n",
    "    print(\"No files uploaded or backend does not support file uploads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea719d5",
   "metadata": {},
   "source": [
    "### Checking Cache Status\n",
    "\n",
    "You can check the status of the context cache for your current knowledge base without running a query. This is useful for verifying if a cache exists and inspecting its properties (TTL, token count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Check cache status\n",
    "status = interpreter.get_cache_status()\n",
    "\n",
    "print(\"Current cache status:\")\n",
    "print(json.dumps(status, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e23820",
   "metadata": {},
   "source": [
    "## Step 3: First Query (Cache Miss)\n",
    "\n",
    "The first query will upload the knowledge base and create a cache.\n",
    "You'll see the full token cost for the KB content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea71ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First query - this creates the cache\n",
    "result1 = interpreter.interpret(\n",
    "    custom_prompt=\"Summarize the key findings regarding global temperature anomalies in 2025 from the WMO report.\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FIRST QUERY RESULTS (Cache Creation)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nResponse:\\n{result1.text[:500]}...\\n\")\n",
    "\n",
    "if result1.usage:\n",
    "    print(f\"Input tokens:  {result1.usage.input_tokens:,}\")\n",
    "    print(f\"Output tokens: {result1.usage.output_tokens:,}\")\n",
    "    print(f\"Cached tokens: {result1.usage.cached_tokens or 0:,}\")\n",
    "    print(\"Cache savings: $0.0000 (Cache Creation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa3a6c",
   "metadata": {},
   "source": [
    "## Step 4: Second Query (Cache Hit)\n",
    "\n",
    "The second query reuses the cached knowledge base.\n",
    "Notice the **cached tokens** are now non-zero, and **cache savings** shows the cost reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second query - this reuses the cache\n",
    "result2 = interpreter.interpret(\n",
    "    custom_prompt=\"What specific outcomes or decisions from COP30 in Belem are mentioned in relation to climate finance?\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SECOND QUERY RESULTS (Cache Hit)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nResponse:\\n{result2.text[:500]}...\\n\")\n",
    "\n",
    "if result2.usage:\n",
    "    print(f\"Input tokens:  {result2.usage.input_tokens:,}\")\n",
    "    print(f\"Output tokens: {result2.usage.output_tokens:,}\")\n",
    "    print(f\"Cached tokens: {result2.usage.cached_tokens or 0:,}\")\n",
    "    print(f\"Cache savings: ${result2.usage.cache_savings or 0.0:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d04ed",
   "metadata": {},
   "source": [
    "## Understanding Cost Savings\n",
    "\n",
    "Context caching provides significant cost savings for repeated queries:\n",
    "\n",
    "| Token Type | Price per 1M tokens | Description |\n",
    "| --- | --- | --- |\n",
    "| Standard Input | $2.00 | Regular input tokens |\n",
    "| Cached Input | $0.50 | Tokens from cache |\n",
    "| Cache Storage | $0.20/hr | Per million cached tokens |\n",
    "\n",
    "**Savings formula**: `(cached_tokens / 1M) * ($2.00 - $0.50) = savings`\n",
    "\n",
    "For a 10,000 token knowledge base queried 10 times:\n",
    "- Without caching: `10 × 10,000 × $2.00/1M = $0.20`\n",
    "- With caching: `10,000 × $2.00/1M + 9 × 10,000 × $0.50/1M = $0.065`\n",
    "- **67% savings!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532310c0",
   "metadata": {},
   "source": [
    "## Step 5: Clear Cache (Optional)\n",
    "\n",
    "You can manually clear the cache if you've updated your knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c862186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the cache to force a refresh\n",
    "interpreter.clear_cache()\n",
    "print(\"Cache cleared. Next query will create a new cache.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4809f488",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "kanoa's context caching feature:\n",
    "\n",
    "1. **Automatically** caches your knowledge base content\n",
    "2. **Reuses** the cache for subsequent queries (same content hash)\n",
    "3. **Saves ~75%** on input token costs for cached content\n",
    "4. **Tracks** cached tokens and savings in the `UsageInfo` object\n",
    "\n",
    "### When to Use Context Caching\n",
    "\n",
    "- ✅ Interactive analysis sessions with multiple queries\n",
    "- ✅ Batch processing against a stable knowledge base\n",
    "- ✅ Knowledge bases > 2,048 tokens (minimum for caching benefit)\n",
    "\n",
    "### When NOT to Use Context Caching\n",
    "\n",
    "- ❌ Single-shot queries (cache creation overhead)\n",
    "- ❌ Rapidly changing knowledge bases\n",
    "- ❌ Very small knowledge bases (< 2,048 tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kanoa-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
