{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24795850",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kanoa'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkanoa\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkanoa\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexample_custom_research\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiExampleCustomResearchBackend\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkanoa\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemini_deep_research\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiDeepResearchBackend\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'kanoa'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import kanoa\n",
    "from kanoa.backends.example_custom_research import GeminiExampleCustomResearchBackend\n",
    "from kanoa.backends.gemini_deep_research import GeminiDeepResearchBackend\n",
    "from kanoa.knowledge_base.base import BaseKnowledgeBase\n",
    "\n",
    "kanoa.options.verbose = 2  # 2=Debug, 1=Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245f8e3",
   "metadata": {},
   "source": [
    "## Example 1: Google AI Studio's Gemini Deep Research Backend\n",
    "\n",
    "Uses the `google.genai` **Interactions API** for multi-step research with web search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51254842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded API key from /home/lhzn/.gemini/api-key-studio\n"
     ]
    }
   ],
   "source": [
    "# Load API key from ~/.gemini/api-key-studio\n",
    "from pathlib import Path\n",
    "\n",
    "key_file = Path.home() / \".gemini\" / \"api-key-studio\"\n",
    "if key_file.exists():\n",
    "    api_key_studio = key_file.read_text().strip()\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = api_key_studio\n",
    "    print(f\"‚úÖ Loaded API key from {key_file}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Key file not found: {key_file}\")\n",
    "    print(\"   Run: gemini-mode setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50d28a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions API available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_153527/3589826578.py:7: UserWarning: Interactions usage is experimental and may change in future versions.\n",
      "  has_interactions = hasattr(client, \"interactions\")\n"
     ]
    }
   ],
   "source": [
    "# Check if Interactions API is available\n",
    "try:\n",
    "    from google import genai\n",
    "\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if api_key:\n",
    "        client = genai.Client(api_key=api_key)\n",
    "        has_interactions = hasattr(client, \"interactions\")\n",
    "        print(f\"Interactions API available: {has_interactions}\")\n",
    "        if not has_interactions:\n",
    "            print(\n",
    "                \"‚ö†Ô∏è Interactions API not found. Upgrade: pip install --upgrade google-genai\"\n",
    "            )\n",
    "    else:\n",
    "        print(\n",
    "            \"‚ö†Ô∏è GOOGLE_API_KEY not set. Get one at: https://aistudio.google.com/apikey\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"Error checking Interactions API: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392c8340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Official Deep Research Backend initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Official Backend\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    try:\n",
    "        backend_official = GeminiDeepResearchBackend(\n",
    "            api_key=api_key,\n",
    "            max_research_time=600,  # 10 minutes\n",
    "            enable_thinking_summaries=True,\n",
    "        )\n",
    "        print(\"‚úÖ Official Deep Research Backend initialized\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è Could not initialize: {e}\")\n",
    "        print(\"Skipping to Proxy Backend example...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GOOGLE_API_KEY not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d965bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<div style=\"background: rgba(186, 164, 217, 0.12);\n",
       "            border: 1px solid rgba(186, 164, 217, 0.35);\n",
       "            border-left: 3px solid rgba(186, 164, 217, 0.75);\n",
       "            padding: 14px 18px;\n",
       "            margin: 10px 0;\n",
       "            border-radius: 6px;\n",
       "            font-size: 0.9em;\n",
       "            line-height: 1.5;\n",
       "            font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Mono', 'Droid Sans Mono', 'Source Code Pro', monospace;\n",
       "            box-sizing: border-box;\n",
       "            max-width: 100%;\n",
       "            overflow-x: auto;\n",
       "            word-wrap: break-word;\">\n",
       "\n",
       "<div style=\"font-weight: 600; margin-bottom: 10px; font-size: 1.1em; opacity: 0.9;\">kanoa</div>\n",
       "<div style=\"opacity: 0.5;\">Starting Gemini Deep Research interpretation</div>\n",
       "<div style=\"opacity: 0.5;\">Research query built: Research Focus: \n",
       "Research the AI industry's response to Gemini 3's release in mid-2025.\n",
       "\n",
       "Focus on:\n",
       "1. What new AI models did OpenAI, Anthropic, and other competitors release in Q4 2025 (after Gemini 3</div>\n",
       "<div style=\"opacity: 0.5;\">Agent config: {'type': 'deep-research', 'thinking_summaries': 'auto'}</div>\n",
       "<div style=\"opacity: 0.85;\">Starting google.genai Interactions API research</div>\n",
       "<div style=\"opacity: 0.85;\">Interaction started: v1_Chc5VkJGYWJlWEo1M2hfdU1QbWZIRDRRdxIXOVZCRmFiZVhKNTNoX3VNUG1mSEQ0UXc</div>\n",
       "<div style=\"opacity: 0.5;\">Step 1: **Verifying Research Premise**\n",
       "\n",
       "I am initiating the research by first addressing a significant chron</div>\n",
       "<div style=\"opacity: 0.5;\">Step 2: \n",
       "\n",
       "**Information Gaps and Strategy**\n",
       "\n",
       "My primary information gap is the confirmation of the central e</div>\n",
       "<div style=\"opacity: 0.5;\">Step 3: \n",
       "\n",
       "**Next Steps: Immediate Searches**\n",
       "\n",
       "To resolve the premise, I plan to execute immediate searches f</div>\n",
       "<div style=\"opacity: 0.5;\">Step 4: \n",
       "\n",
       "**Timeline Confirmation**\n",
       "\n",
       "I've synthesized the initial search results and have confirmed that the</div>\n",
       "<div style=\"opacity: 0.5;\">Step 5: \n",
       "\n",
       "**New Model Landscape**\n",
       "\n",
       "The late 2025 period was marked by rapid innovation across the industry. </div>\n",
       "<div style=\"opacity: 0.5;\">Step 6: \n",
       "\n",
       "**Strategic and Market Reaction**\n",
       "\n",
       "The market reaction suggests Gemini 3 was viewed as a 'giant, u</div>\n",
       "<div style=\"opacity: 0.5;\">Step 7: \n",
       "\n",
       "**Refining Research Focus**\n",
       "\n",
       "To provide a complete picture of the post-Gemini 3 landscape, my next</div>\n",
       "<div style=\"opacity: 0.5;\">Step 8: \n",
       "\n",
       "**Finalizing Chronology and Scope**\n",
       "\n",
       "I have successfully grounded the research in the appropriate </div>\n",
       "<div style=\"opacity: 0.5;\">Step 9: \n",
       "\n",
       "**Gathering Final Competitive Context**\n",
       "\n",
       "Before concluding, I synthesized information regarding ma</div>\n",
       "<div style=\"opacity: 0.5;\">Step 10: \n",
       "\n",
       "**Concluding the Research Phase**\n",
       "\n",
       "I have collected a comprehensive set of facts, including specif</div>\n",
       "<div style=\"opacity: 0.5;\">Step 11: **Verifying Hypothetical Scenario**\n",
       "\n",
       "I am beginning the process of verifying a detailed candidate re</div>\n",
       "<div style=\"opacity: 0.5;\">Step 12: \n",
       "\n",
       "**Targeting Specific Claims**\n",
       "\n",
       "The candidate response is extremely specific, providing exact model</div>\n",
       "<div style=\"opacity: 0.5;\">Step 13: \n",
       "\n",
       "**Next Verification Steps**\n",
       "\n",
       "I have formulated a batch of searches targeting the core claims: the </div>\n",
       "<div style=\"opacity: 0.5;\">Step 14: \n",
       "\n",
       "**Verifying Key Release Dates**\n",
       "\n",
       "I have successfully verified the critical timeline details based </div>\n",
       "<div style=\"opacity: 0.5;\">Step 15: \n",
       "\n",
       "**Confirmed Industry Response**\n",
       "\n",
       "The major strategic moves by competitors are largely confirmed. I</div>\n",
       "<div style=\"opacity: 0.5;\">Step 16: \n",
       "\n",
       "**Information Gaps Remain**\n",
       "\n",
       "While the core narrative is robustly supported, a few highly specific</div>\n",
       "<div style=\"opacity: 0.5;\">Step 17: \n",
       "\n",
       "**Next Steps: Targeted Search**\n",
       "\n",
       "To resolve these remaining minor discrepancies, I will perform a </div>\n",
       "<div style=\"opacity: 0.5;\">Step 18: \n",
       "\n",
       "**Verifying Key AI Releases**\n",
       "\n",
       "I have completed the iterative verification process for all specifi</div>\n",
       "<div style=\"opacity: 0.5;\">Step 19: \n",
       "\n",
       "**Resolving Minor Date Discrepancy**\n",
       "\n",
       "A minor chronological detail needed attention: the candidate</div>\n",
       "<div style=\"opacity: 0.5;\">Step 20: \n",
       "\n",
       "**Confirming Industry Shifts and Metrics**\n",
       "\n",
       "All auxiliary claims, including the competitive breakt</div>\n",
       "<div style=\"opacity: 0.5;\">Step 21: \n",
       "\n",
       "**Conclusion of Verification**\n",
       "\n",
       "Having synthesized all available information and verified nearly e</div>\n",
       "<div style=\"opacity: 0.5;\">Received text delta: 21469 chars</div>\n",
       "<div style=\"opacity: 0.85;\">Research complete. Final text: 21469 chars</div>\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Research Complete!\n"
     ]
    }
   ],
   "source": [
    "# Run research query (demonstrates real-time web research beyond model's training cutoff)\n",
    "research_query = \"\"\"\n",
    "Research the AI industry's response to Gemini 3's release in mid-2025.\n",
    "\n",
    "Focus on:\n",
    "1. What new AI models did OpenAI, Anthropic, and other competitors release in Q4 2025 (after Gemini 3's release)?\n",
    "2. How did the tech press and AI researchers react to Gemini 3's capabilities and benchmarks?\n",
    "3. What strategic shifts or pricing changes occurred in the AI market following Gemini 3's launch?\n",
    "\"\"\"\n",
    "\n",
    "if \"backend_official\" in globals():\n",
    "    # Use the kanoa backend API directly with elegant display handling\n",
    "    result = backend_official.interpret(\n",
    "        focus=research_query,\n",
    "        stream=True,\n",
    "        display_result=True,  # Backend wrapper handles all display logic\n",
    "    )\n",
    "\n",
    "    # Iterate through chunks (display happens automatically via display_result=True)\n",
    "    for _chunk in result:\n",
    "        pass  # Status chunks logged via kanoa's logging system (lavender block)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Research Complete!\")\n",
    "else:\n",
    "    print(\"Skipped (backend not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c125191",
   "metadata": {},
   "source": [
    "## Example 2: Example Custom Research Backend (Artisanal Request Refinement)\n",
    "\n",
    "Uses **Gemini 3 Pro + RAG + Google Search** for enterprise/Vertex AI accounts.\n",
    "\n",
    "This is a reference implementation of a two-step research process:\n",
    "1. **RAG**: Retrieve context from internal knowledge base\n",
    "2. **Search**: Use Google Search to verify/expand on the prompt\n",
    "3. **Synthesis**: Generate a grounded response\n",
    "\n",
    "*Why?*\n",
    "\n",
    "The official GeminiDeepResearchBackend uses the Interactions API, which is\n",
    "only available to AI Studio accounts. Vertex AI accounts lack access to this API.\n",
    "GeminiExampleCustomResearchBackend was implemented as a workaround, using Gemini Pro\n",
    "directly, combining web search + custom RAG for equivalent functionality. It provides\n",
    "a model for roll-your-own research backends.\n",
    "\n",
    "### 2a. With Local RAG Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple text-based knowledge base\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Simple KB implementation for demo purposes\n",
    "class SimpleTextKB(BaseKnowledgeBase):\n",
    "    \"\"\"Simple text-based knowledge base for demo.\"\"\"\n",
    "\n",
    "    def __init__(self, directory: str):\n",
    "        self.directory = Path(directory)\n",
    "        self.documents = {}\n",
    "        self._load_documents()\n",
    "\n",
    "    def _load_documents(self):\n",
    "        \"\"\"Load all .txt files from directory.\"\"\"\n",
    "        for txt_file in self.directory.glob(\"*.txt\"):\n",
    "            self.documents[txt_file.name] = txt_file.read_text()\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5) -> list[str]:\n",
    "        \"\"\"Simple keyword-based retrieval.\"\"\"\n",
    "        results = []\n",
    "        query_lower = query.lower()\n",
    "\n",
    "        for content in self.documents.values():\n",
    "            if query_lower in content.lower():\n",
    "                results.append(content)\n",
    "                if len(results) >= top_k:\n",
    "                    break\n",
    "\n",
    "        return results if results else list(self.documents.values())[:top_k]\n",
    "\n",
    "\n",
    "# Create temp KB directory with Gemini 3 analysis documents\n",
    "kb_dir = Path(tempfile.mkdtemp()) / \"gemini3_analysis\"\n",
    "kb_dir.mkdir()\n",
    "\n",
    "# Add Bridgewater's bullish perspective (real)\n",
    "(kb_dir / \"bridgewater_analysis.txt\").write_text(\"\"\"\n",
    "Bridgewater Associates: \"Google's Gemini 3 Means AI's Resource Grab Phase Is On\"\n",
    "Published: November 26, 2025\n",
    "Authors: Greg Jensen (Co-CIO), Jas Sekhon (AIA Labs Chief Scientist)\n",
    "\n",
    "KEY TAKEAWAYS:\n",
    "- Gemini 3 is the best publicly available model in terms of raw intelligence\n",
    "- Biggest jump in frontier model capabilities since OpenAI's o3 (6+ months ago)\n",
    "- First significantly larger model release showing pre-training scaling continues\n",
    "- Used 2-3x more compute than GPT-4o, possibly 10x more\n",
    "- Strongly multimodal: excels at text, image, and video generation/interpretation\n",
    "- Google is now the clear leader in the AI race\n",
    "- Trained entirely on Google's own TPU chips, showcasing vertical integration advantage\n",
    "\n",
    "COMPETITIVE LANDSCAPE:\n",
    "- Anthropic's Claude Opus 4.5 released after Gemini 3\n",
    "- Opus 4.5 likely best for coding, but trails Gemini 3 in general intelligence\n",
    "- First time since GPT-3.5 (3 years ago) that OpenAI doesn't have a leading model\n",
    "- DeepSeek V3.2 acknowledged gap with Gemini 3 due to smaller pre-training compute\n",
    "\n",
    "MARKET IMPLICATIONS:\n",
    "- Massive capex boom coming in 2026-2027\n",
    "- Pre-training scaling laws validated, justifying continued compute investments\n",
    "- Google's position poses major risk to Nvidia's market share\n",
    "- \"Barnes & Noble moment\" getting closer - widespread AI adoption imminent\n",
    "- Boost to global economy underappreciated in current markets\n",
    "\n",
    "SOURCE: https://www.bridgewater.com/research-and-insights/googles-gemini-3-means-ais-resource-grab-phase-is-on\n",
    "\"\"\")\n",
    "\n",
    "# Add skeptical research firm perspective (fabricated)\n",
    "(kb_dir / \"skeptical_research_note.txt\").write_text(\"\"\"\n",
    "Meridian Analytics - Gemini 3 Research Note\n",
    "Date: December 3, 2025\n",
    "Author: Dr. Sarah Chen, Chief Technology Analyst\n",
    "\n",
    "\"The Gemini 3 Hype Cycle: Separating Signal from Noise\"\n",
    "\n",
    "EXECUTIVE SUMMARY:\n",
    "We believe the market's enthusiasm for Gemini 3 is premature and overlooks significant\n",
    "red flags in Google's announcement. Our analysis suggests the performance gains are\n",
    "overstated and the strategic positioning is weaker than claimed.\n",
    "\n",
    "KEY CONCERNS:\n",
    "\n",
    "1. CHERRY-PICKED BENCHMARKS\n",
    "- Google selected benchmarks that favor multimodal capabilities\n",
    "- Missing critical real-world task evaluations\n",
    "- No independent validation of claimed 2-3x compute scaling\n",
    "- Suspiciously timed release before year-end portfolio reviews\n",
    "\n",
    "2. COST ECONOMICS DON'T ADD UP\n",
    "- If Gemini 3 truly used 10x more compute, inference costs should be prohibitive\n",
    "- Google hasn't disclosed pricing for API access\n",
    "- TPU advantage may be offset by lack of ecosystem support\n",
    "- Bridgewater's \"whatever it takes\" spending thesis ignores margin compression risks\n",
    "\n",
    "3. COMPETITIVE MOAT OVERSTATED\n",
    "- Claude Opus 4.5's coding superiority matters more for enterprise adoption\n",
    "- OpenAI's o3 mini shows efficiency gains trump raw scale\n",
    "- Vertical integration is a liability when chip architectures shift\n",
    "- Developer ecosystem still heavily Nvidia/CUDA-centric\n",
    "\n",
    "4. TIMING RAISES QUESTIONS\n",
    "- Announced during market uncertainty about AI capex sustainability\n",
    "- Convenient narrative shift from \"efficient AI\" back to \"scale at all costs\"\n",
    "- Follows disappointing Gemini 2.5 reception earlier in year\n",
    "- Reads like attempt to reclaim mindshare after losing ground to Anthropic\n",
    "\n",
    "MARKET IMPACT ASSESSMENT:\n",
    "- Short-term boost to Google stock likely, but fundamentals unchanged\n",
    "- Capex boom narrative may accelerate market correction fears\n",
    "- Nvidia vulnerability thesis is premature - ecosystem lock-in remains strong\n",
    "- Real test will be enterprise adoption rates in Q1 2026\n",
    "\n",
    "RECOMMENDATION:\n",
    "We maintain our HOLD rating on Alphabet. Wait for:\n",
    "1. Independent benchmark validation\n",
    "2. Pricing disclosure\n",
    "3. Real-world deployment metrics\n",
    "4. Competitor responses (especially OpenAI's GPT-5)\n",
    "\n",
    "The \"resource grab\" framing feels like retroactive justification for Google's\n",
    "high spending rather than evidence of sustainable competitive advantage.\n",
    "\"\"\")\n",
    "\n",
    "# Add academic critique (fabricated)\n",
    "(kb_dir / \"academic_perspective.txt\").write_text(\"\"\"\n",
    "MIT Technology Policy Working Group - Position Paper\n",
    "\"Gemini 3 and the Illusion of Intelligence Scaling\"\n",
    "December 8, 2025\n",
    "\n",
    "Authors: Prof. James Nakamura (MIT CSAIL), Dr. Emily Rodriguez (Stanford HAI)\n",
    "\n",
    "ABSTRACT:\n",
    "We challenge the dominant narrative that Gemini 3 represents meaningful progress\n",
    "in artificial intelligence. Our analysis suggests that Google's approach exemplifies\n",
    "the industry's confusion between computational scale and genuine intelligence gains.\n",
    "\n",
    "TECHNICAL ANALYSIS:\n",
    "\n",
    "1. Benchmark Gaming Has Reached Its Limit\n",
    "- We replicated 12 of Gemini 3's benchmark tests using publicly available versions\n",
    "- Found significant variance (¬±15%) depending on prompt engineering\n",
    "- Model exhibits classic \"brittleness\" - excellent on training distribution,\n",
    "  poor on slight perturbations\n",
    "- \"Humanity's Last Exam\" performance likely reflects training data contamination\n",
    "\n",
    "2. Multimodal Capabilities Are Oversold\n",
    "- Video understanding shows surface pattern matching, not causal reasoning\n",
    "- Image generation quality vs. Midjourney/DALL-E 3 is subjective at best\n",
    "- Integration between modalities is shallow - still mostly separate encoders\n",
    "- No evidence of genuine cross-modal reasoning\n",
    "\n",
    "3. The Pre-Training Scaling Myth\n",
    "- Bridgewater's celebration of \"2-3x compute\" ignores diminishing returns\n",
    "- Our estimates suggest 70% of Gemini 3's improvement comes from post-training\n",
    "- Data quality bottleneck is real - Google hasn't solved the synthetic data problem\n",
    "- Compute scaling without algorithmic breakthroughs hits ceiling around 2026\n",
    "\n",
    "4. Societal Implications Being Ignored\n",
    "- Energy consumption of training Gemini 3: estimated 150-200 GWh\n",
    "- Carbon footprint equivalent to 30,000 homes' annual electricity\n",
    "- Inference costs make democratization impossible\n",
    "- Concentrates AI power in hands of three companies (Google, OpenAI, Anthropic)\n",
    "\n",
    "COMPETITIVE REALITY CHECK:\n",
    "Contrary to Bridgewater's \"clear leader\" claim, we see a three-way stalemate:\n",
    "- Google: Multimodal breadth, but weak developer ecosystem\n",
    "- OpenAI: Best reasoning and API reliability, but falling behind on raw benchmarks\n",
    "- Anthropic: Enterprise trust and safety, coding excellence\n",
    "\n",
    "The \"Barnes & Noble moment\" thesis is particularly troubling - it assumes businesses\n",
    "will adopt AI regardless of ROI. Our surveys show enterprise AI adoption is *slowing*\n",
    "due to implementation challenges, not accelerating.\n",
    "\n",
    "POLICY RECOMMENDATIONS:\n",
    "1. Mandate independent benchmark auditing for AI capability claims\n",
    "2. Require energy/carbon disclosure for model training\n",
    "3. Investigate potential anti-competitive effects of vertical integration\n",
    "4. Fund public alternatives to prevent oligopoly capture\n",
    "\n",
    "CONCLUSION:\n",
    "Gemini 3 is an impressive engineering achievement, but not the paradigm shift\n",
    "Bridgewater describes. The \"resource grab\" is better understood as an arms race\n",
    "driven by FOMO rather than genuine capability gains. We urge caution before\n",
    "accepting industry narratives that justify unsustainable spending.\n",
    "\n",
    "The most dangerous aspect of Gemini 3's release is not the model itself, but\n",
    "the framing that more compute + more data = inevitable progress. This deterministic\n",
    "view ignores fundamental questions about what intelligence means and whether\n",
    "current architectures can achieve it.\n",
    "\"\"\")\n",
    "\n",
    "# Add contrarian investor perspective (fabricated)\n",
    "(kb_dir / \"contrarian_investor.txt\").write_text(\"\"\"\n",
    "Blackstone Alternatives - AI Sector Deep Dive\n",
    "\"Why We're Shorting the Gemini 3 Narrative\"\n",
    "December 10, 2025\n",
    "\n",
    "Investment Thesis: BEARISH on AI Infrastructure Spend Post-Gemini 3\n",
    "\n",
    "MARKET CONTEXT:\n",
    "Bridgewater's \"resource grab\" thesis has created euphoria in AI infrastructure stocks.\n",
    "Nvidia +18%, ASML +12%, data center REITs +15% since Gemini 3 announcement.\n",
    "We believe this rally is disconnected from fundamentals.\n",
    "\n",
    "OUR CONTRARIAN VIEW:\n",
    "\n",
    "1. CAPEX PEAK, NOT BEGINNING\n",
    "Bridgewater says 2026-2027 will see \"biggest capex boom of our lives.\"\n",
    "We see evidence of the opposite:\n",
    "- Microsoft's FY26 guidance shows AI capex *declining* 8% YoY\n",
    "- Meta's Reality Labs spending cuts signal cooling enthusiasm\n",
    "- Amazon's data center construction permits down 23% vs 2024\n",
    "- Enterprise AI project cancellation rate at 34% (Gartner)\n",
    "\n",
    "Google's Gemini 3 might be the *last gasp* of the scaling paradigm, not the beginning.\n",
    "\n",
    "2. UNIT ECONOMICS DON'T WORK\n",
    "Simple math that Bridgewater ignores:\n",
    "- If Gemini 3 uses 10x compute, costs must scale similarly\n",
    "- Current GPT-4 API is marginally profitable at best\n",
    "- Where is 10x revenue growth to justify 10x cost increase?\n",
    "- Google's AI Services revenue growth: only 12% QoQ (slowing)\n",
    "\n",
    "The \"pay whatever it takes\" assumption requires believing companies will accept\n",
    "negative ROI indefinitely. We don't buy it.\n",
    "\n",
    "3. ENTERPRISE ADOPTION PLATEAU\n",
    "Survey of 500 Fortune 1000 companies (conducted Dec 2025):\n",
    "- 78% have \"AI initiatives\" (sounds good!)\n",
    "- Only 12% report measurable productivity gains (not good)\n",
    "- 61% cite \"complexity and cost\" as barriers to scaling\n",
    "- 45% plan to *reduce* AI spending in 2026\n",
    "\n",
    "The \"Barnes & Noble moment\" requires businesses to fear disruption. Instead, we see\n",
    "AI fatigue. Most companies tried chatbots, got mediocre results, moved on.\n",
    "\n",
    "4. GOOGLE'S VERTICAL INTEGRATION IS A LIABILITY\n",
    "Bridgewater frames TPU ownership as advantage. We see it differently:\n",
    "- TPUs have 4% market share vs Nvidia's 88%\n",
    "- Developer tooling ecosystem is GPU-centric (CUDA, PyTorch)\n",
    "- Training on TPUs, deploying on GPUs creates friction\n",
    "- Google's history: Wave, Google+, Stadia (vertical integration ‚â† success)\n",
    "\n",
    "5. THE ANTHROPIC FACTOR\n",
    "Claude Opus 4.5's coding superiority is more valuable than Gemini 3's benchmarks:\n",
    "- 67% of enterprise AI spend goes to coding assistants\n",
    "- GitHub Copilot has 1.8M paid subscribers (growing 40% annually)\n",
    "- Code generation has clear ROI; \"general intelligence\" doesn't\n",
    "- Anthropic's Constitutional AI approach builds trust (Google doesn't)\n",
    "\n",
    "TECHNICAL ANALYSIS:\n",
    "We hired independent ML researchers to evaluate Gemini 3:\n",
    "\"Marginal improvement over Claude Opus 4.0. Not a step function change.\n",
    "Bridgewater's 'biggest jump since o3' claim appears exaggerated.\"\n",
    "\n",
    "SCENARIO PLANNING:\n",
    "\n",
    "BULL CASE (20% probability):\n",
    "- Gemini 3 triggers enterprise FOMO, spending accelerates\n",
    "- OpenAI responds with GPT-5, validates capex boom thesis\n",
    "- 2026-2027 sees sustained AI infrastructure demand\n",
    "- Bridgewater's \"resource grab\" proves prescient\n",
    "\n",
    "BASE CASE (50% probability):\n",
    "- Gemini 3 impact fades after 2-3 quarters\n",
    "- AI spending continues but doesn't accelerate\n",
    "- Market realizes \"scaling laws\" are slowing, not accelerating\n",
    "- Google, OpenAI, Anthropic settle into stable competition\n",
    "\n",
    "BEAR CASE (30% probability):\n",
    "- Major AI project failures in Q1 2026 shake confidence\n",
    "- Enterprises demand ROI proof before further spending\n",
    "- Nvidia's margin compression accelerates as Google sells TPUs\n",
    "- \"AI winter 2.0\" narrative takes hold by late 2026\n",
    "\n",
    "INVESTMENT STRATEGY:\n",
    "- SHORT: Nvidia, AI infrastructure ETFs, data center REITs\n",
    "- LONG: Anthropic-linked opportunities (if available), efficiency AI startups\n",
    "- NEUTRAL: Alphabet (Gemini 3 impact offset by search business pressure)\n",
    "\n",
    "CONCLUSION:\n",
    "Bridgewater's thesis requires three things we don't believe:\n",
    "1. Pre-training scaling continues indefinitely (we see signs of plateauing)\n",
    "2. Businesses spend irrationally on AI (they're already pulling back)\n",
    "3. Gemini 3 represents paradigm shift (it's incremental improvement)\n",
    "\n",
    "The \"resource grab\" narrative feels like late-cycle euphoria, not early-cycle opportunity.\n",
    "We're positioning for the correction.\n",
    "\n",
    "DISCLOSURE: This report reflects proprietary analysis and should not be construed\n",
    "as investment advice. Blackstone Alternatives holds short positions in several\n",
    "securities mentioned.\n",
    "\"\"\")\n",
    "\n",
    "# Initialize Knowledge Base\n",
    "kb = SimpleTextKB(str(kb_dir))\n",
    "print(f\"‚úÖ Knowledge Base created with {len(list(kb_dir.glob('*.txt')))} documents\")\n",
    "print(\"\\nDocuments loaded:\")\n",
    "for doc in sorted(kb_dir.glob(\"*.txt\")):\n",
    "    print(f\"  - {doc.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Research Backend\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") or os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "backend_proto = GeminiExampleCustomResearchBackend(\n",
    "    api_key=api_key,\n",
    "    model=\"gemini-2-5-flash\",  # Use flash for cost efficiency\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Gemini Research Backend initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee376e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run research with RAG context\n",
    "result = backend_proto.interpret(\n",
    "    context=\"Conflicting analyses of Google's Gemini 3 release from November 2025\",\n",
    "    focus=\"\"\"Compare and contrast the perspectives on Gemini 3's impact:\n",
    "\n",
    "    1. How do Bridgewater, MIT researchers, and Blackstone Alternatives differ\n",
    "       in their assessment of Gemini 3's capabilities?\n",
    "    2. What are the key points of disagreement about the AI 'resource grab' thesis?\n",
    "    3. Who makes the most compelling argument about Gemini 3's competitive position?\n",
    "    4. What real-world evidence would validate or refute each perspective?\"\"\",\n",
    "    stream=True,\n",
    "    display_result=True,\n",
    "    knowledge_base=kb,  # Pass KB here via kwargs\n",
    ")\n",
    "\n",
    "# Iterate through chunks to display results\n",
    "for _chunk in result:\n",
    "    pass  # Display happens via display_result=True\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Research Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f9c78",
   "metadata": {},
   "source": [
    "### 2b. Without RAG (Web Search Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research without internal knowledge base (web search only)\n",
    "result = backend_proto.interpret(\n",
    "    focus=\"\"\"What did OpenAI announce or release in response to Google's Gemini 3\n",
    "    in late 2025? Specifically look for:\n",
    "    - GPT-5 or o4 announcements\n",
    "    - Pricing changes\n",
    "    - Strategic partnerships\n",
    "    - Public statements from Sam Altman or OpenAI leadership\"\"\",\n",
    "    stream=True,\n",
    "    display_result=True,\n",
    ")\n",
    "\n",
    "# Iterate through chunks to display results\n",
    "for _chunk in result:\n",
    "    pass  # Display happens via display_result=True\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Research Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411de66d",
   "metadata": {},
   "source": [
    "## Example 3: GDrive Grounding (Official Backend Only)\n",
    "\n",
    "The official backend supports grounding against your **Google Drive documents**.\n",
    "\n",
    "### Setup (One-time)\n",
    "\n",
    "1. Go to [AI Studio](https://aistudio.google.com/)\n",
    "2. Create a **File Search Store**\n",
    "3. Upload documents from your GDrive\n",
    "4. Copy the store name (format: `fileSearchStores/your-store-id`)\n",
    "5. Set environment variable:\n",
    "\n",
    "```bash\n",
    "export GEMINI_FILE_SEARCH_STORE=\"fileSearchStores/your-store-id\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b328f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for File Search Store\n",
    "store_name = os.getenv(\"GEMINI_FILE_SEARCH_STORE\")\n",
    "\n",
    "if store_name and \"backend_official\" in globals():\n",
    "    # Re-initialize with File Search\n",
    "    backend_with_gdrive = GeminiDeepResearchBackend(\n",
    "        api_key=api_key,\n",
    "        file_search_stores=[store_name],\n",
    "        max_research_time=600,\n",
    "    )\n",
    "\n",
    "    # Use the kanoa backend API directly\n",
    "    result = backend_with_gdrive.interpret(\n",
    "        focus=\"Summarize our team's recent quantum computing research findings\",\n",
    "        stream=True,\n",
    "        display_result=True,\n",
    "    )\n",
    "\n",
    "    # Iterate through chunks to display results\n",
    "    for _chunk in result:\n",
    "        pass  # Display happens via display_result=True\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"GDrive-Grounded Research Complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GDrive grounding not configured.\")\n",
    "    print(\"Set GEMINI_FILE_SEARCH_STORE to test this feature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232d3bb",
   "metadata": {},
   "source": [
    "## Choosing the Right Backend\n",
    "\n",
    "| Use Case | Backend | Why |\n",
    "|----------|---------|-----|\n",
    "| **Free-tier student/researcher** | `GeminiDeepResearchBackend` | Access to official Deep Research agent, GDrive grounding |\n",
    "| **Enterprise with Vertex AI** | `GeminiExampleCustomResearchBackend` | Works with Vertex AI credentials, custom RAG |\n",
    "| **Need multi-step reasoning** | `GeminiDeepResearchBackend` | Built-in thought summaries, plan generation |\n",
    "| **Need custom knowledge base** | `GeminiExampleCustomResearchBackend` | Full control over RAG context |\n",
    "| **GDrive document grounding** | `GeminiDeepResearchBackend` | Native File Search integration |\n",
    "| **Cost optimization** | `GeminiExampleCustomResearchBackend` | Can use Gemini Flash for cheaper inference |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Integration**: See `tests/integration/test_deep_research.py` for testing patterns\n",
    "- **Documentation**: Check the [Deep Research Guide](../docs/source/user_guide/deep_research.md)\n",
    "- **Contribute**: Help us test the official backend when SDK 2.0 is released!\n",
    "\n",
    "Happy researching! üîç‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kanoa-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
